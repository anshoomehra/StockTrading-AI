{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Financial Instruments\n",
    "\n",
    "Momentum\n",
    "\n",
    "Alpha\n",
    "\n",
    "Inferential Stats:\n",
    "Null Hypothesis : https://blog.minitab.com/blog/understanding-statistics/things-statisticians-say-failure-to-reject-the-null-hypothesis\n",
    "\n",
    "Signal\n",
    "Noise\n",
    "Signal/Noise Ratio\n",
    "\n",
    "Stock Arbitrage \n",
    "\n",
    "Normality (Normal Distribution) : It is important that our samples & results demostrate normal distribution \n",
    "\n",
    "Probablity Distribution (It is probability that RANDOM SAMPLE set demostrate [tyeOfDistribution] distrution occurs with [xyz] probability \n",
    "> Probablity Distrubution Functions (PDFs) or Type of Distrubutions\n",
    "<img src=\"Images/1.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "\n",
    "What if the Distrbutions are not Standard Normal, & has deviations, how can they can be adjusted to Standard Normal? See the Quiz below, mu is mean & sigma is standard deviatiom \n",
    "<img src=\"Images/2.png\" width=\"500\" height=\"500\" aligh=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terms to know:\n",
    "\n",
    "1. Quartiles\n",
    "2. Deciles\n",
    "3. Quantiles\n",
    "\n",
    "<img src=\"Images/6.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/7.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/8.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Rest below will be covered during content below \n",
    "4. IQR (Inter-quartile Range)\n",
    "5. Whiskers\n",
    "6. Outliers\n",
    "7. Long Tails\n",
    "8. Fat Tails\n",
    "9. Skewness / Kurtosis\n",
    "\n",
    "\n",
    "\n",
    "How do we know that data can be described Normally?? To understand this, there are various tests which can be done as kistd below ...\n",
    "\n",
    "\n",
    "\n",
    "**Comparing Tests for Normality**\n",
    "\n",
    "There are some visual ways to check if a distribution is normally distributed or not. Recall that normal distributions are symmetric and do not have fat tails (a more formal term for “fat tails” is kurtosis”). Box-whisker plots helps us visually check if a distribution is symmetric or skewed. A histogram lets us check if a distribution is symmetric/skewed, and if it has fat tails. \n",
    "\n",
    "<img src=\"Images/3.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "For Normal Distribution:\n",
    "1. Mean is same as Median\n",
    "2. First Quartile and 3rd Quartile are at same distance\n",
    "3. Whiskers are at same distance\n",
    "\n",
    "<img src=\"Images/4.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "So how would a Box Plot and Histogram look for data which is not Normal. Below is example of Left Long Fat Tail. Characteristics\n",
    "1. Long tail on one side of the distribution\n",
    "2. Mean lies left to the Median (It is also called as Distrbution is Left Skewed)\n",
    "** In fact stock return tend to exibit left skewed & fat tail, which means, extreme negative returns could occur with greater frequency \n",
    "\n",
    "<img src=\"Images/5.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "To have more thorough test of Normality, we can perform QQ Plot. QQ plots help us compare any two distributions, so they can be used to compare distributions other than the normal distribution. If you plot the actual data’s distribution against a theoretical normal distribution, you can decide if the distributions are the same type if the QQ plot produces a fairly straight line.\n",
    "\n",
    "<img src=\"Images/9.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Normal Distribution QQ Plot - as it draws straight line\n",
    "<img src=\"Images/10.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Not Normal Distribution QQ Plot - as it draws curve line\n",
    "<img src=\"Images/11.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "What if we want single number to test Normality?? If so, we can define threshold which can ease our process of finding Normality i.e. we can define a thereshold like in example below of 5% saying anything above that is Normal and vice-versa, there are few tests which can help achive the goal as listed below.  \n",
    "\n",
    "<img src=\"Images/12.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "There are three hypothesis tests that can be used to decide if a data distribution is normal. These are,\n",
    "1. The Shapiro-Wilk test\n",
    "2. D’Agostino-Pearson, and\n",
    "3. The Kolmogorov-Smirnov test. \n",
    "\n",
    "Each of these produce p-value, and if the p-value is small enough, say 0.05 or less, we can say with a 95% confidence that the data is not normally distributed. Shapiro-Wilk tends to perform better in a broader set of cases compared to the D’Agostino-Pearson test. In part, this is because the D’Agostino-Pearson test is used to look for skewness and kurtosis that do not match a normal distribution, so there are some odd non-normal distributions for which it doesn’t detect non-normality, where the Sharpiro-Wilk would give the correct answer.\n",
    "\n",
    "The Kolmogorov Smirnov test can be used to compare distributions other than the normal distribution, so it’s similar to the QQ plot in its generality. To do a normality test, we would first rescale the data distribution (subtract the mean and divide by its standard deviation), then compare the rescaled data distribution with the standard normal distribution (which has a mean of zero and standard deviation of 1). In general, the Shapiro-WIlk test tends to be a better test than the Kolmogorov Smirnov test, but not in all cases.\n",
    "\n",
    "<img src=\"Images/13.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "So in summary, if you want to be thorough, you can use all three tests (there are even more tests that we haven’t discussed here). If you only want to use one test, use the Shapiro-Wilk test. For a sanity check, visualize your data distribution with a histogram, box-whisker plot, and/or a QQ plot.\n",
    "\n",
    "References <br>\n",
    "Shapiro-Wilk test : https://en.wikipedia.org/wiki/Shapiro%E2%80%93Wilk_test <br>\n",
    "D’Agostino-Pearson : https://en.wikipedia.org/wiki/D%27Agostino%27s_K-squared_test <br>\n",
    "\n",
    "Kolmogorov-Smirnov : https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stationary Data**: Another thing we must ensure if that data we have is stationary overtime, which means that mean, variance, covariance are same overtime. This can be tested via **Breusch-Pagan Test** which tests 2 properties, Homoscedastic or Heteroskedastic, Homoscedastic mean the data is stationary & Heteroskedastic means it is not-stationary.\n",
    "<br><br>\n",
    "**Homoscedastic vs Heteroskedastic <br>**\n",
    "\n",
    "One of the assumptions of linear regression is that its input data are homoscedastic. A visual way to check if the our data is homoscedastic is a scatter plot \n",
    "<br>\n",
    "If our data is heteroscedastic, a linear regression estimate of the coefficients may be less accurate (further from the actual value), and we may get a smaller p-value than should be expected, which means we may assume (incorrectly) that we have an accurate estimate of the regression coefficient, and assume that it’s statistically significant when it’s not.\n",
    "\n",
    "<img src=\"Images/14.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/15.png\" width=\"500\" height=\"500\" aligh=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> What if our data is Not Normal & Heteroskedastic -- How do we fix this?? </b>\n",
    "\n",
    "We can look or rate of change and apply log on it, one very popular technique to achieve this is Box-Cox Transformation\n",
    "\n",
    "<img src=\"Images/16.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/17.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/18.png\" width=\"500\" height=\"500\" aligh=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Regression, Multiple Regression, Multi-variate Regression Quick Refresher:** <br>\n",
    "When we build model where one independent variable is used to predict one dependent variable we called it regression, and since we assume that data is lineary seperable, we draw a stright line drawing prediction for dependent variable and hence called Linear Regression. Example: House Price as dependent variable, relying on House Square Footage as independent variable with equation for line as y= mx + c (m is coifficient & c is intercerpt and these can be represented in many different ways like beta, alpha etc) <br>\n",
    "\n",
    "<img src=\"Images/20.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Models goal is to draw the optimal line which makes accurate predictions, however, in reality how much ever optimal line is drawn it can't make 100% accurate predictions, i.e. some error is expected, the error is drawn below as distance from actual to the predicted point (drawn as vertical distances) & are also known as Residuals(error term). Hence, our goal is changed to draw a line with least Residucals.\n",
    "\n",
    "<img src=\"Images/21.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/22.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "We can check if our Residuals follow Normal Distribution i.e. mean of zero and a constant statndard deviation, then these Residuals can be considered Random, by Random we mean that prediction made by model is equally likely be higher or lower than the actual value. If however, te average of the residuals is not zero, this gives us hint that the model has bias in prediction errors.\n",
    "\n",
    "<img src=\"Images/23.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/24.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "**Multiple Regerssion:** Continuing from above, if we see Bias, one way to improve this situation would be to introduce other inpendent variables, and this is called Multiple Regerssion, i.e. we are using more than one independent variable to predict a dependent variable.\n",
    "\n",
    "<img src=\"Images/25.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "**R-Squared** Now, our Gol is to see the model build is performing well, and generalizing predictions, one way this can be done is to do R^2 check on models performance, the value of this test range from 0 to 1. Value of 1 means that all the variations in Dependent Variable can be explained with all the variations in Independent Varaibles. <br>\n",
    "\n",
    "The better metrics is **Adjusted R-Squared** whicj tells us minimum number of independent variables which are most relevant to our model.\n",
    "\n",
    "**F-Test** - Another test which can be performed is called F-Test, whcih tests if Coefficients & Intercept are non-zero & are meaninful, if we get p value < 0.05 that means our model parameters are non-zero and exhibit meaningful relationship.\n",
    "\n",
    "<img src=\"Images/26.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "\n",
    "We studied how multiple independent variables can be used to predict one dependent variable called as Multiple Regression (example, house area, location, # of rooms to predict house price). Now, if we use independent variables to predict multiple dependent variables at the same time is called **Multi-Variate Regression** (example, predicting house price, along with gas & electrcity consumption\n",
    "\n",
    "<img src=\"Images/27.png\" width=\"500\" height=\"500\" aligh=\"left\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Breusch-Pagan Test for Heteroscedasticity (revisited)** <br>\n",
    "<br>\n",
    "Now that we’ve covered regression, let’s look at the Breusch Pagan test in more depth. The Breusch-Pagan test is one of many tests for homoscedasticity/heteroscedasticity. It takes the residuals from a regression, and checks if they are dependent upon the independent variables that we fed into the regression. (Note that we’ll explain residuals in a few videos within this lesson, so feel free to jump back here after you watch the video “Linear Regression”). The test does this by performing a second regression of the residuals against the independent variables, and checking if the coefficients from that second regression are statistically significant (non-zero). If the coefficients of this second regression are significant, then the residuals depend upon the independent variables. If the residuals depend upon the independent variables, then it means that the variance of the data depends on the independent variables. In other words, the data is likely heteroscedastic. So if the p-value of the Breusch-Pagan test is ≤ 0.05, we can assume with a 95% confidence that the distribution is heteroscedastic (not homoscedastic).\n",
    "<br>\n",
    "<br>\n",
    "**Breusch-Pagan Test in Python** <br>\n",
    "<br>\n",
    "In Python, we can use the statsmodels.stats.diagnostic.het_breuschpagan(resid, exog_het) function to test for heteroscedasticity. We input the residuals from the regression of the dependent variable against the independent variables. We also input the independent variables that may affect the variance of the data. The function outputs a p-value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/19.png\" width=\"500\" height=\"500\" aligh=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terms:\n",
    "\n",
    "Non-Stationary Data : Means that the mean and the variance change over time.\n",
    "( \n",
    "\n",
    "What this means for us? So if the data is non-stationary, that means the properties of data change over time, could prove to be conter-productive, as our goal with time series is to use past-data predicting future, and if data is non-stationary, it means that the past data is not very useful to predict future.\n",
    "\n",
    "To counter this in the world of Stocks, \n",
    "1. we use Stock Returns and not prices, since Returns may be more stationary than prices,\n",
    "2. and instead of instead of using returns, we use Log Returns to inhibit properties which are more stationary & evenly distributed  \n",
    "\n",
    ")\n",
    "\n",
    "**AR Models ( Auto Regressive Models )**\n",
    "\n",
    "Auto Regressive models are analogically similar to \"regression\" i.e. they are also follow similar properties, draw a linear seperation i.e. a straight line to draw any predictions based on independent variables. The difference comes in when these models look at history of same independent variable, i.e. seeing data of same variable over various time steps & hence the name autoregression, i.e. regression on self.\n",
    "\n",
    "<img src=\"Images/28.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/29.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "AR Models are defined by Lag, which deteremines how mant previous time steps are used to determine prediction & hence models are named that way, example AR-1 means only one time step prior was used to determine prediction.\n",
    "<img src=\"Images/30.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "To generalize, we refer this as AR(p), i.e. during experimentation stage, various lags can be tested to see which lag value performs the best...\n",
    "<img src=\"Images/31.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "As with any regresison models, Adjusted R-squared test can be used to see models performance.\n",
    "\n",
    "<img src=\"Images/32.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "What if we have multiple time series, if we have multiple time series, since AR model is specific to time series, multiple AR models can be build for each time-series.\n",
    "\n",
    "<img src=\"Images/33.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "However, what if the these multiple time-series have impact on each other i.e. movement of one stock having impact on other, similar to multivariate-multiple regression, we can also have multi-variate version of AR models which are called Vector AR Models.\n",
    "\n",
    "<img src=\"Images/34.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "\n",
    "**MA Models ( Moving Average Models )**\n",
    "In contrast to AR where models relies on prior value of the stock price, Moving Average as name indicates relies on Moving Averages lineraly combined with Residual's or Error Terms (in essence past predictions and actuals delta) . Since the model relies on residulas, which in technical terms has no prior relationship, this model can help uncover sudden changes in the data called white noise.\n",
    "\n",
    "<img src=\"Images/35.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "MA models are also called as MA(q) where q is lag (smilar to AR models) - to find the best value of q can be determined by plotting AutoCorrelation plot, what this tells us is relation between 2 given data points, in this example, we are studying lags and how each value of lag impact prediction, autocorelation is not regression, as regression, multiple factors are combined to collectively see impact on dependent varaible where as corelation measures pair-wise relation between two periods at a time ...\n",
    "\n",
    "<img src=\"Images/36.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "So how to read the correlation plot? We would want to use the highly positive and highly negative correlation plot -- (rember highly positively shows strong correlation with positive slope (upward line) and highly negative show strong correlation with negative slope (downward line), so both +1 and -1 strong corelation indicators, values close to zero +ve or -ve means no or little correlation), once we hit values with very little corerlation we should ideally use lag to ignore those values.\n",
    "\n",
    "<img src=\"Images/37.png\" width=\"500\" height=\"500\" aligh=\"left\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARMA (Auto Regressive Moving Averages) \n",
    "\n",
    "AR & MA models both capture different characteristics -\n",
    "<br>AR(p) models try to explain the momentum and mean reversion effects often observed in trading markets (market participant effects).\n",
    "<br>\n",
    "MA(q) models try to capture the shock effects observed in the white noise terms. These shock effects could be thought of as unexpected events affecting the observation process e.g. Surprise earnings, wars, attacks, etc.\n",
    "\n",
    "<img src=\"Images/38.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Nice is that, we can get both of these characteristics in model by combining them like below, where p is lag for AR and q is lag for MA:\n",
    "\n",
    "<img src=\"Images/39.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARMA (Auto Regressive Intergrated Moving Averages) \n",
    "\n",
    "Variation of ARMA is ARIMA (Auto Regressive Intergrated Moving Averages). This concept is used in trading strategy called Paris Trading.\n",
    "\n",
    "Taking difference between each period is called 'Time Difference' or 'Item-wise difference' - If we take time-difference of data, we may be able to describe data more easily as a constant-number. If we see the example below, first graph is position of tutle, second is the speed:\n",
    "\n",
    "If we take the derivative of straight-line (first graph), it gives us the slope of the line, slope is single number which can help describe the line with a constant. If we want to go back to position from speed, we can do intergral, this is finding the area under the curve or finding cumulative sum which is nothing but position of turtle in this case.\n",
    "\n",
    "<img src=\"Images/40.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Let's use the fundamentals and apply these to financial data / stocks data.\n",
    "\n",
    "One of the fundamental requirement of ARMA is that data is stationary, if data is non-stationary, which makes it hard to use past to predict future. One way to translate this data into Stationary is to look at time-difference between data, in other words rate of change of the data over certian period, which can be current price divided by previous price. To convert this in to logs, it will be current log price minus previous log price.\n",
    "\n",
    "<img src=\"Images/41.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/42.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "In Assets world, it is considered that their time difference is stationary i.e. their Returns are more stationary than Prices. \n",
    "\n",
    "In math terms, we say that it's\n",
    "    Prices are Intergated of Order 1\n",
    "    And it's Log Returns are Integated of Order 0\n",
    "    \n",
    "<img src=\"Images/43.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "So now, we are look at the data and perform \"Augmented Dicky Fuller Test' to see if data is stationary or not. If data is not stationary, we can then perform time-difference & perform the test again as show below:\n",
    "\n",
    "<img src=\"Images/44.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "However, if we data is again non-statinary after first time-difference, another time difference can be applied until we hit stationary data, this is denoted by D value, where D tells, how many times the time-difference is computed. And say that original data is Intergated of Order D (in below example 3) before it turned stationary.\n",
    "\n",
    "<img src=\"Images/45.png\" width=\"500\" height=\"500\" aligh=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonal Adjustments using ARIMA (SARIMA)\n",
    "Time series data tends to have seasonal patterns. For instance, natural gas prices may increase during winter months, when it’s used for heating homes. Similarly, it may also increase during peak summer months, when natural gas generators are used to produce the extra electricity that is used for air conditioning. Retail sales also has expected increases during the holiday shopping season, such as Black Friday in the US (November), and Singles’ Day in China (also in November).\n",
    "\n",
    "Stocks may potentially have seasonal patterns as well. One has to do with writing off losses in order to minimize taxes. Funds and individual investors have unrealized capital gains or losses when the stock price increases or decreases from the price at which they bought the stock. Those capital gains or losses become “realized capital gains” or “realized capital losses” when they sell the stock. At the end of the tax year (which may be December, but not necessarily), an investor may decide to sell their underperforming stocks in order to realize capital losses, which may potentially reduce their taxes. Then, at the start of the next tax year, they may buy back the same stocks in order to maintain their original portfolio. This is sometimes referred to as the “January effect.”\n",
    "\n",
    "Removing seasonal effects can help to make the resulting time series stationary, and therefore more useful when feeding into an autoregressive moving average model.\n",
    "\n",
    "To remove seasonality, we can take the difference between each data point and another data point one year prior. We’ll refer to this as the “seasonal difference”. For instance, if you have monthly data, take the difference between August 2018 and August 2017, and do the same for the rest of your data. It’s common to take the “first difference” either before or after taking the seasonal difference. If we took the “first difference” from the original time series, this would be taking August 2018 and subtracting July 2018. Next, to take the seasonal difference of the first difference, this would mean taking the difference between (August 2018 - July 2018) and (August 2017 - July 2017).\n",
    "\n",
    "You can check if the resulting time series is stationary, and if so, run this stationary series through an autoregressive moving average model.\n",
    "\n",
    "Side Note\n",
    "Kendall Lo, one of the subject matter experts of our course, recommends this book: “Way of the Turtle: The Secret Methods that Turned Ordinary People into Legendary Traders”. The book is about how a successful investor trained his students (his “turtles”) to follow his trend-following trading strategy. The book illustrates the concepts of using trading signals, back-testing, position sizing, and risk management. The story is also summarized in this article Turtle Trading: A Market Legend [ https://www.investopedia.com/articles/trading/08/turtle-trading.asp ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kalman Filter\n",
    "\n",
    "What we have studied thus far is that ARMA/ARIMA requires p & q lags to be defined, and these hyper-parameters has huge impact on the performance of the model. What if the previous instead of n lag is represnted by t-1 state itself, this is where Kalman Filter comes in as all prior state observations are represented in t-1 state as single state. Below is high level view of how does Kalman Filter works, just as side note, studied this during Autonomous Car Nanodegree and was dealt in quite detail there.\n",
    "\n",
    "<img src=\"Images/46.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/47.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "As we have seen above, we have noisy data as real-estate and we also have smooth ideal signal curve, which we know after  the fact if past. Kalman filter learn prediction, and see how off it is, further take that feedback and improve the model as shown below, this is high level inution on how all the past observations are translated to single state.\n",
    "\n",
    "<img src=\"Images/48.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "**Kalman Filters for Pairs Trading**\n",
    "One way Kalman Filters are used in trading is for choosing the hedge ratio in pairs trading. We will get into pairs trading and hedge ratios in lesson 13 of this module, but for now, imagine that there’s a magic number that you can estimate from a model, such as a regression model, based on time series data of two stocks.\n",
    "\n",
    "Every day when you get another data point, you can run another regression and get an updated estimate for this number. So do you take the most recent number every time? Do you take a moving average? If so, how many days will you average together? Will you give each day the same weight when taking the average?\n",
    "\n",
    "All of these kinds of decisions are meant to smooth an estimate of a number that is based on noisy data. The Kalman Filter is designed to provide this estimate based on both past information and new observations. So instead of taking a moving average of this estimate, we can use a Kalman Filter.\n",
    "\n",
    "The Kalman Filter takes the time series of two stocks, and generate its “smoothed” estimate for this magic number at each new time period. Kalman Filters are often used in control systems for vehicles such as cars, planes, rockets, and robots. They’re similar to the application in pairs trading because they take noisy indirect measurements at each new time period in order to estimate state variables (location, direction, speed) of a system .\n",
    "\n",
    "Kalman Filters are not used in this module’s project, but if you want to learn more, please check out the extracurricular content section: \"Machine Learning\": Introduction to Kalman Filters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Particle Filter\n",
    "\n",
    "It is a type of Genetic Algorithm, by genetic we mean that we apply natural selection to improve the estimates. Partcile filter can be explained with intution of deploying little helpers to make stock predictions, idea is to monitor and provide incentive to helpers who are making right predictions and penalize helpers who can are making bad predictions. Evetually in this process only good helps stay and bad ones are eliminated, since this process demonstrate natural selection, it is referred as type of genetic algorithm. Little helpers are called particles whose parameters are set randomly.\n",
    "\n",
    "<img src=\"Images/53.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "When more particles show similar predictions or are consentrated, this shows confidence in predictions.\n",
    "\n",
    "<img src=\"Images/50.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "However, when predictions are speard out, or partciles show non-similar predictions this shows lack in confidence in predictions.\n",
    "<img src=\"Images/52.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Particle filters are good with handling variety of data as they do not expect data to be normally distributed.\n",
    "Parctile filters do not assume linear relationship so they can fit non-linear data\n",
    "<img src=\"Images/51.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN \n",
    "\n",
    "Will not cover any notes here, look at other Jupter for in depth on RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volatility\n",
    "\n",
    "Volatility is important measure of risk. But what is risk, risk is uncertianity about future & uncertainity about bad thing happening, like loosing all money invested in stocks. We can depict this as standard deviation from the mean of log return, so it measures the dispursion of the log return from the actual log return...\n",
    "\n",
    "<img src=\"Images/54.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "So volatility gives you sense of range of values log return will fall into. Let's say over the years, we have studied log return and say that they more or less depict normal distribution, since we know that for normal distribution 95% of data falls under 2 standard deviation +/-, hence if we know the mean and volatility, we can easily compute range of gain as shown in example below ...\n",
    "\n",
    "<img src=\"Images/55.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "So why spend so much time studying this, prime reason is that it gives investors sense of what risk they have and what shoudl they expect wrt log returns or how much can they differe from expected, just broadly listing some uses below .. (alpha below means, what investment to trade vs not trade, like defining startegy/portfolio)\n",
    "\n",
    "<img src=\"Images/56.png\" width=\"500\" height=\"500\" aligh=\"left\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how do we calculate the Volatility ?\n",
    "\n",
    "It is basically nothing but calcualting the standard deviation of the data, in our case stock returns, so let's first calculate the stock returns.\n",
    "\n",
    "<img src=\"Images/57.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "The first datum point will not have prior, it will be NAN, so if you now start with n+1 data, you will have n log returns\n",
    "\n",
    "<img src=\"Images/58.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Formula for Volatility (standard deviation) is \n",
    "\n",
    "<img src=\"Images/59.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Key point here is that since Volatility is defined as standard-deviation, it treats log returns below and above the mean the same way, as they are squared while computing standard deviation.\n",
    "\n",
    "Note below some examples, where we are calculating Volatility for different periods in this case, Days vs Weeks, and as it may be evident that Volatility is higher for Weeks as there is possibility of higher price fluctuations expected on weekly data vs Daily Data ..\n",
    "\n",
    "<img src=\"Images/60.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "However, investors would like to see the Volatility which can be compared across data sets and various market situations and hence ideally Annual frequency is used for Volatility comparison, now if we do not have data for several years progression, we can use whatever frequency data we have and extraplote them, and it is called **Annualized Volatility** \n",
    "\n",
    "<img src=\"Images/61.png\" width=\"500\" height=\"500\" aligh=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Annualized Volatility** -- if we do not have data for Annual progressions to calculate Volatility, we can use whatever frequency data we have and extraplote them, and it is called **Annualized Volatility**\n",
    "\n",
    "<img src=\"Images/62.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "So formula to calculate the yearly or monthly progression from daily to yearly or monthly to to yearly is below, note 252 is the number of trading days in an year and 12 offcourse is the number of months. \n",
    "\n",
    "<img src=\"Images/63.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "So why Square-root & not just multiply by #'s directly? \n",
    "\n",
    "As a quick refresher Natural Log returns sum over-time..\n",
    "\n",
    "<img src=\"Images/64.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Following the analogy, annual log return is the sum of monthly log-returns.\n",
    "\n",
    "<img src=\"Images/65.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Now, let's say that return of each month is Random vriable, which means that it depicts random phenomina & the likelihood that it can take different values can be represented by Probability distributions.\n",
    "\n",
    "<img src=\"Images/66.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Now, let's few assumptions.\n",
    "1. That the log returns of each month have same distributions\n",
    "2. let's say these returns are independent, which means that log return if one month does not depend on other month.\n",
    "\n",
    "<img src=\"Images/67.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Now, we let's say that Annual Log Return is another Random Variable which equates sum of monthly log-returns. recall what it mean to sum random variables, you can generate the distribution of the sum by repeatedly taking sets of samples from each of the Constituent Distributions & summing them.\n",
    "\n",
    "<img src=\"Images/68.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "So, we have setup the situation but let's remember our goal, we want to relate the standard deviation of the distrubutions of Monthly log returns to the standard deviation of the distrubutions of Annual log returns.\n",
    "\n",
    "<img src=\"Images/69.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "So now, we are going to use the key fact that whenever you sum independent random variables that variance of the sum equals sum of the variances\n",
    "\n",
    "<img src=\"Images/70.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Getting back to the calculation:\n",
    "we now know that Variance of the Annual Log Returns is equal to the Variance of the SUM of Monthly Log Returns.\n",
    "\n",
    "<img src=\"Images/71.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Since, we assumed that monthly log returns were independent, we can also similarly reflect that Variance of the Annual Log Returns is equal to the SUM of Monthly Log Returns Variances\n",
    "\n",
    "<img src=\"Images/72.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Since variance is the square of standard deviation, we can re-write the equation as below:\n",
    "\n",
    "<img src=\"Images/73.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "But, we also assumed that the standard deviations of the monthly log returns were all the same value Sigma Month, so we wend up with 12 factors of Sigma Month. When we do  the square root, we can see the same equation in terms of standard deviation (instead of variance).\n",
    "So this way, we can annulaize the monthly log returns.\n",
    "\n",
    "<img src=\"Images/74.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Similarly, if you want to annulaize the weekly log returns or daily log returns, it can be done similarly as \n",
    "\n",
    "<img src=\"Images/75.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/76.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rolling Windows\n",
    "\n",
    "So we know how to calculate the volatility for a period but in practice we need to see volatility over broader horizon/periods to compare the trend, as it is evident from below graph that S&P 500 dropped significantly in 2008-2009 period and then it had very dramatic trend since then...\n",
    "\n",
    "<img src=\"Images/77.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "So to get broader specturm for volatility, we can adopt rolling widows, which essentially gives us volatility for a period and then be compared or be seen as trend, example below ...\n",
    "\n",
    "<img src=\"Images/78.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/79.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "So how long this time window should be, one-week, one-month, one-year or anything else, \n",
    "<img src=\"Images/80.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "   Long window means that the value you compute may not react to market conditions as much\n",
    "   Short window means that the value you compute will have more sensitive reaction to market conditions and may not be that realiable\n",
    "    \n",
    "hence, it all depends on the stratgey and individual needs.\n",
    "\n",
    "<img src=\"Images/81.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/82.png\" width=\"500\" height=\"500\" aligh=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponentially Weighted Moving Average\n",
    "\n",
    "If we look at the specturm of the data, the stock movement as of yesterday is more relevant than the 2 months back data. However, we were thus far looking at moving averages which gives equal weightage to 2 months old data vs the most recent, which is not right. To fix this, we can add weight to the equation which will help the old data relevance decay with time, example below:\n",
    "\n",
    "<img src=\"Images/83.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "So how do we compute this <br>\n",
    "\n",
    "Let's start with formula of historical volatility:\n",
    "\n",
    "<img src=\"Images/84.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Let's add t subscript to show todays volatility, and square both sides, remeber squaring both sides gives us nothing but variance...\n",
    "\n",
    "<img src=\"Images/85.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Let's make key assumptions,\n",
    "1. That mean log return is zero, it is ok to do as when you do compute return for short interval, their mean is relatively small as compared to their standard deviation.\n",
    "\n",
    "    <img src=\"Images/86.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "2. Now let's change n-1 to n, this influence does not impact much when n is large.\n",
    "\n",
    "    <img src=\"Images/87.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "    \n",
    "So if we see the final equation, it is nothing but the average of the squared log returns in which each of the log returns are weighted equally.\n",
    "\n",
    "   <img src=\"Images/88.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "   \n",
    "So now to make it weighted avergae, let's add a new factor called lambda, lambda is value between 0 & 1, and in this case it is expected to lower down gradually to mellow the impact of the past return and highlight the impact of recent returns\n",
    "\n",
    "   <img src=\"Images/89.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "   \n",
    "<br>\n",
    "So now let's put it all together, we will start with \\( \\lambda^0 \\) which is nothing but 1, and gradually keep increasing it to \\( \\lambda^1 \\), \\( \\lambda^2 \\), \\( \\lambda^3 \\) and so on .. & to make it weighted, divide by the sum of all lambdas\n",
    "\n",
    "   <img src=\"Images/90.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Well this equation threw me off to start with, as it appears that the lambda is increasing with time in past and working in reverse but this is **really veru very interesting equation, as you may see if the starting value of lambda is large it decrease exponentially and if we start is small it increases eponentually** - have done some sample examples below to demostrate this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-dfe99e39affc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m.2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mn_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m.2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m.2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m.2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mn_sum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m.9\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.9\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.9\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "n = pd.DataFrame({'a':[.2**0, .2**1, .2**2]})\n",
    "n_sum = .2**0 + .2**1 + .2**2\n",
    "print (n/n_sum)\n",
    "\n",
    "n = pd.DataFrame({'a':[.9**0, .9**1, .9**2]})\n",
    "n_sum = .9**0 + .9**1 + .9**2\n",
    "print (n/n_sum)\n",
    "\n",
    "print(\"\")\n",
    "print (\"And Just for the fun, to see the impact f big values more prominent & reversing the trend from higher-to-lower to lower-to-higher\")\n",
    "\n",
    "n = pd.DataFrame({'a':[2**0, 2**1, 2**2]})\n",
    "n_sum = 2**0 + 2**1 + 2**2\n",
    "print (n/n_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(10))\n",
    "df = pd.DataFrame(np.arange(2, 10, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pct_change() #periods=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ewm(alpha=0.1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecasting Volatility\n",
    "\n",
    "Now we know how to calculate volatility, can we forecast volatility, as that is what most important to us to anticipate the market..\n",
    "\n",
    "- General thinking is that Volatiliy is easier to predict than the Stock Price\n",
    "- Volatility Trend is deemed Sticky, which means one Volatile day is antcipated to be followed by another Volatile Day, some trends below..\n",
    "\n",
    "<img src=\"Images/91.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "To predict Volatility, we can use special form of Auto Regression called **ARCH (Autogeressive Conditionally Hetroscedastic)**\n",
    "Autogeressive means that, present value is somehow related to the recent past values.\n",
    "<br>\n",
    "Hetroscedastic means that variable we are trying to model may have different magnitudes of vriability at different time points. Magnitude of variability is usually measured as variance.\n",
    "<br>\n",
    "Conditional menas that Hetroscedastic property is dependent on previous value or values of this variable.\n",
    "\n",
    "So ARCH formula is very similar to the what we have studied thus far as EMA, the current variance is weight sum of past squared log rerturns, but we think weights as parameters of the models.\n",
    "\n",
    "<img src=\"Images/92.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "But see here, we are only dependent on the log returs, we can also do the same with adding prior variance is dependeny to further generalize it, which also known as **GARCH ( Generalized Autogeressive Conditionally Hetroscedastic ) ** \n",
    "\n",
    "<img src=\"Images/93.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "   \n",
    "these can be parameterized as m,n, where m is # of log return terms and n is number of variance terms..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So what causes the Volatility??\n",
    "\n",
    "Most of the people think that some news about the company or asset create price fluctuations, however, study shows that variance in price between days is the leading factor, that is trading itself cause the volatility, higher the volume of trade higher the volatility. So one define various staratigies to be formed on trading volatility, let's look at some observations around these contexts.\n",
    "\n",
    "First one is Mean Reversion\n",
    "<img src=\"Images/94.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Second - In low-volatility times, momentum stratigies may work better.\n",
    "\n",
    "Third - When market is going up Volatility is down, when market is going down Volatility is high. Because of this Volatility is popular media as gauge for fear. To see this in action, let's see VIX index in contrast to S&P ( VIX is nothing but Volatility Index )\n",
    "\n",
    "<img src=\"Images/95.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "So can one trade VIX, yes humans will turn anything into tradable entity, VIX is tradable and not just that there is VVIX, which is an index over VIX which can be further traded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to make use of Volatility??\n",
    "\n",
    "some examples below :\n",
    "\n",
    "<img src=\"Images/96.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Let's see what these mean below...\n",
    "\n",
    "**Limiting Universe** means that one can adopt strategy specific to volatility index, low volatility securities show a pattern that they come back to their running mean after the spikes, this can be capatilized, one can buy at spike knowing that prices will hit mean, example below ...\n",
    "\n",
    "<img src=\"Images/97.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Another obseravtion is that low-volatility stocks, outperform high-volatility stocks, but why this happens remain as mystry. One hypothesis could be  that people ignore boring things in light of exciting stocks... And this could be stratgy itself, below are some ETFs which capatilize on low-volatility stocks and have funds spin-off to just focus on them, we will talk about ETF later.\n",
    "\n",
    "<img src=\"Images/98.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "\n",
    "**Normalize by Volatility** means that volatility to be used normalizing. Example say we have momentum signal which says that NFLX and Walmart both has 30% return, this may seems to mean that both are performing same, hwoever, as we know that MFLX can spike 30% return in just a week in contrast to walmart, **so to normalize these spikes, we can divide the returns with Volatility. This is very common practice to compare assets apple-to-apple, specifically when you are comparing them against universe of unrelated stocks.**\n",
    "\n",
    "**Volatility helping with Position Sizes** In general Quants utilize smaller position sizes in their strartegies when markets are volatile, to minimize the volatility of net profits!! commonly called P&L, ( profit and loss ). Generally, P&L across portfolio is measured to see performance and volatility can come in play to define the sizes.\n",
    "\n",
    "<img src=\"Images/99.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "So how do we use it in defining position sizes, one of the formulas which can be used is below this will translate to smaller posoition sizes for more expensive and more volatile assets & this is can auto-adjust the portfolio with market adjustents.\n",
    "\n",
    "<img src=\"Images/100.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "This can vbe further gated with thersholds, i.e. to trigger sell or buy defining how much profit or loss one can take in this investment, these are defined as 'take profit level' and 'stop loss level'\n",
    "\n",
    "<img src=\"Images/101.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "However, during high volatile market situations these thresholds reach much sooner than anticipated, and generally analysts adjust them when markets are higly volatile\n",
    "\n",
    "<img src=\"Images/102.png\" width=\"500\" height=\"500\" aligh=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some other breakout strategies\n",
    "\n",
    "**Bollinger Bands** Continuing idea of theresholds we just discussed above, one way to know sell and buy signals is look at standard deviation, i.e. the rolling window, and look at mean if the stock prices in that rolling window, drawing the standard deviation for these rolling windows. Then draw the two standard deviation above and below the rolling mean, this will give is bracket to operate on i.e. trend on price fluctuations -- these lines are called Bollinger Bands. That is if the price say spike up the upper band, but then start return may generate sell signal, and vice-versa, if the price dip below the lower band but start to go up, though not at the bottom but still low can be signal for purchase.\n",
    "\n",
    "**This strategy may work well for stocks whose prices fluctuate but return to the running mean **\n",
    "\n",
    "<img src=\"Images/103.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "However, for stocks where trend is not that variable in nature and it keeps going up, but never hits the upper Bollinger Band as show below\n",
    "\n",
    "<img src=\"Images/104.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "For this trend, the upper & lower band instead of 2 standard deviations can be instead used as Max & Min of Rolling Windows\n",
    "\n",
    "<img src=\"Images/105.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "and one strategy can be formed for this pattern is to define Long Position when price tops rolling max and Short position when price bottoms rolling min.\n",
    "\n",
    "<img src=\"Images/106.png\" width=\"500\" height=\"500\" aligh=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairs Trading and Mean Reversion\n",
    "\n",
    "Before we go in to Paris Trading, some fundamentals on which Paris Trading rely are Mean Reversion and Corelation.\n",
    "\n",
    "**Mean Reversion**, We alerady studied that mean reversion stands for stock price pattern where stock price come back to it's mean post fluctuations. However, during high volatility segments or situations like recession, there may be new mean which may define the new state.\n",
    "\n",
    "<img src=\"Images/106.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Analysts generally do not depend on one stock as such to study patterens, they attempt to pool **corelated stocks** and study the trends in tandum to have more holistic understanding if market, by corelated I mean stocks whose nature of business, valuation, price fluctuations & county of operation has strong relationship with stock being compared with. So given this if one stock reflect pattern which is dramatically different than other, we can assume that this deviation is perhaps temporary and has high proability to revert back to it's mean in future. \n",
    "\n",
    "<img src=\"Images/107.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "To define Mean Reversion mathematically, we will define a model called **Drift & Volatility** Model. In simple words we can say that price of the stock is nothing but sum of it's long term average (Drift) + some randomness (Volatility)\n",
    "\n",
    "**Stock Price = Drift + Volatility**\n",
    "\n",
    "<img src=\"Images/108.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "\n",
    "So mathematically, we can represent it as:\n",
    "\n",
    "<img src=\"Images/109.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Details below:\n",
    "\n",
    "<img src=\"Images/110.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/111.png\" width=\"500\" height=\"500\" aligh=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So let's bring it all together **\n",
    "\n",
    "To carry foward what we studied thus far, we saw concepts of mean reversion & also how stocks can be related or seen in pairs, now the hypothesis building on these concepts is that, if we know of pair of stocks which are related say one company sell peas and other carrots and say tat both are related as these prodicts are sold in pairs then we can determine trends or RELATIVE DIFFERENCES between these two trends, and if we see one diverging from mean then these to generate signals for Short or Long positions. See example below:\n",
    "\n",
    "<img src=\"Images/112.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "So there are advantages to trade in pairs, as broader news say jobs data may move all stocks down, however that signal may not be very helpful to make trade decisions, hence seeing the relative difference between pairs combined with that news may generate more confident signal to Short or Long. \n",
    "\n",
    "It may be good to know that though our expectation is that stocks converge back to mean 'over a period of time' - this time period could be in days, weeks, months or may never converge & stratgies must play this factor to define stop loss, should something like this happen to cut down losses.\n",
    "\n",
    "So how do we describe relatve differences between the stocks -\n",
    "\n",
    "**Relative difference is defined by Spread and Hedge Ratios** -- basically our goal is to define ratio of these stocks whcih balance out each other.\n",
    "\n",
    "<img src=\"Images/113.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Note that with pairs trading, we analyze the original stock price series, and do not convert them to returns or log returns. We’ll get into the details shortly, but let’s just look at an example. Let’s say stock_Astock \n",
    "A\n",
    "​\t  is $2 per share, and stock_Bstock \n",
    "B\n",
    "​\t  is $3 per share. If we figured out that we can trade these pairs together, we may go long stock_Astock \n",
    "A\n",
    "​\t  and short stock_Bstock \n",
    "B\n",
    "​\t . But how much do we long stock_Astock \n",
    "A\n",
    "​\t  and short stock_Bstock \n",
    "B\n",
    "​\t ? What if we long 3 shares of stock_Astock \n",
    "A\n",
    "​\t  and short 2 shares of stock_Bstock \n",
    "B\n",
    "​\t ? This is nice, because shares_A \\times price_A - shares_B \\times price_Bshares \n",
    "A\n",
    "​\t ×price \n",
    "A\n",
    "​\t −shares \n",
    "B\n",
    "​\t ×price \n",
    "B\n",
    "​\t  gives us 3 \\times \\$2 - 2 \\times \\$33×$2−2×$3, or zero. Doing pairs trading analysis with the stock price series instead of returns lets us decide how many shares of each stock to long or short, since our goal will be to have the same dollar amount in our long position as in our short position.\n",
    "\n",
    "So to compure this, we first find out the Hedge Ratio, which can be computed two ways\n",
    "\n",
    "<img src=\"Images/114.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Once we know the Hedge Ration, we find the Spread as shown below, this may apper very familiar as it is nothing but finding 'Error Term/Residual' of a Linear Regression (refersher Y - Y_hat). So what below equation is trying is to give us is a model of predicting B depending on A, and estimation Spread that is the variance of price of Stock B minus Estimation of Stock Price B.\n",
    "\n",
    "<img src=\"Images/115.png\" width=\"500\" height=\"500\" aligh=\"left\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** SO NEXT BIG Q is HOW DO WE FIND PAIRS FOR TRADES**\n",
    "\n",
    "There could be many factors, and different stratifies can be applied here, somple examples -\n",
    "\n",
    "1. Economic Similarities, depending on say -\n",
    "    - Government Policies: We can say hypothetically that steel stocks are influenced by Govt Polocies in US and may have +/-ve impact in accordance.\n",
    "    - Supply Chain: We can say hypothetically that stocks or chips and dependent on iPhone Sales, a drop in iPhone Sales or vice-versa may signal drop in other Stock.\n",
    "    - Similarly other signals which make pairs depend on each other.\n",
    "    \n",
    "2. Time Zones -  \n",
    "Time zones play very important role for international stocks, say that economic news on Stock A in US may always signal rise in Stock B in India, difference between US and India can play huge role defining strategy when to Buy or Sell Stock B, and these can be cascaded, as if such signals prevail, cascading stocks markets like Germay which comes after India can be leveraged to execute certain stocks in that segment repeaing overall gain.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/116.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/118.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/117.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "CoIntegration is not same as Correlation \n",
    "\n",
    "Correlation means when Stock A move up, Stock B moves up, ane vice-versa!\n",
    "\n",
    "CoIntegration means that over a range of days relative increase in A is matched by relative increase in B, lets say we but Stock A worth of $100, and Stocb worth of $100, over a period of time we will see that relative values  remain the same.\n",
    "<img src=\"Images/119.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "So what is important for Pairs Trading is CoInegration and the way to find out of Stocks are CoInegrated is done by Engle-Granger Test --\n",
    "<img src=\"Images/120.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "<img src=\"Images/121.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "<img src=\"Images/122.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/123.png\" width=\"500\" height=\"500\" aligh=\"left\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how do we find similar stocks - if we go with analyzing all the stocks it will take lon time, once possible way is to group them by business segments - \n",
    "\n",
    "<img src=\"Images/124.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "But this is very obvious, we would want relationships beyond their business domain, one of the very popular techniques to find similar relationships is by unsupervised Clustering - and this help us find relationships beyond business domains and the ones which hard to study manually.\n",
    "\n",
    "<img src=\"Images/125.png\" width=\"500\" height=\"500\" aligh=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "It is also important to define how 2 stocks are diverging from their spread, for this we need to define the threshold, and if we hit the threshold, we will know that it will return back to it's mean ... \n",
    "\n",
    "<img src=\"Images/126.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "So when to short or go long ... \n",
    "\n",
    "<img src=\"Images/127.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/128.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/129.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "The way we caculate these threasholds is by checking how many standard viation awat from historical mean ...\n",
    "<img src=\"Images/130.png\" width=\"500\" height=\"500\" aligh=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back Testing\n",
    "\n",
    "Very similar to general ML Training, Testing, I will skip explanation...\n",
    "<img src=\"Images/131.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/132.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/133.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/134.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "<img src=\"Images/135.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/136.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/137.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "\n",
    "SUMMARY \n",
    "\n",
    "<img src=\"Images/138.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/139.png\" width=\"500\" height=\"500\" aligh=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/140.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/141.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/142.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "What is an INDEX ?\n",
    "\n",
    "<img src=\"Images/143.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/144.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "More than one Index are called Indicies\n",
    "<img src=\"Images/145.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "<img src=\"Images/146.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/147.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/148.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/149.png\" width=\"500\" height=\"500\" aligh=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/150.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/151.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/152.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/153.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/154.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "<img src=\"Images/155.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/156.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/157.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/158.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/159.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "<img src=\"Images/160.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/161.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "<img src=\"Images/162.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/163.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "<img src=\"Images/164.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "<img src=\"Images/165.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/166.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/167.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/168.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/169.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/170.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "<img src=\"Images/171.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/172.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "<img src=\"Images/173.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/174.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "<img src=\"Images/175.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/175.5.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/176.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/177.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/178.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/179.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/180.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/181.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/182.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/183.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/184.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/185.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/186.png\" width=\"500\" height=\"500\" aligh=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/187.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/188.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/189.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/190.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/191.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "<img src=\"Images/192.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/193.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "<img src=\"Images/194.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/195.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/196.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "<img src=\"Images/197.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/198.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/199.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "<img src=\"Images/200.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/201.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/202.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/203.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/204.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "<img src=\"Images/205.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/206.png\" width=\"500\" height=\"500\" aligh=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio RIsk and Return\n",
    "\n",
    "1. Diversification\n",
    "<img src=\"Images/207.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/208.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Let's see how do diversify the portflio & calculate the gains/strategies based on that ....\n",
    "\n",
    "<img src=\"Images/209.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Weights are nothing but distribution weightage\n",
    "\n",
    "<img src=\"Images/210.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "So to calculate portfolio's mean, variance return we will use below formula .. \n",
    "\n",
    "Note that we will need various scenarios (these could be time windows) to come in play to predict the future and that is denoted by 'i'\n",
    "\n",
    "Let's start with PORTFOLIO MEAN: \n",
    "<img src=\"Images/211.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/212.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/213.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/214.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "SO now lets see the PORTFOLIO VARIANCE\n",
    "<img src=\"Images/215.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/216.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/217.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "So we know that corelation factor spans between -1 & 1, strongly coorelated stocks would have factor of 1 and the coorelation value far away from 1 signal non-coorelation\n",
    "\n",
    "So let;s assume if stocks are strongly corerlated the replace this factor by 1, what this tells us that portfolio std. deviation is nothing but weighted average of the individual stocks std deviation.\n",
    "\n",
    "<img src=\"Images/218.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "So other corelation factors less than 1 signals the porfilio's std. deviation is less than weighted average of the individual stocks std deviation.\n",
    "\n",
    "So what if corelation factors is -1 \n",
    "\n",
    "In this case portfolio std. deviation is nothing but weighted diffrence of the individual stocks std deviation.\n",
    "\n",
    "<img src=\"Images/219.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "In the case of corelatoon is -1, we get perfectly hedged portfolio by soliving below equation and this signals that variance between 2 stocks is zero, but in reality becuase of market other factors it never reaches 0.\n",
    "\n",
    "<img src=\"Images/220.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "\n",
    "Optional on how these portflio variance is derived \n",
    "\n",
    "<img src=\"Images/221.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "\n",
    "So how does this help us reducing the risk ... \n",
    "\n",
    "\n",
    "<img src=\"Images/222.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Optional - \n",
    "\n",
    "\n",
    "<img src=\"Images/223.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/224.png\" width=\"500\" height=\"500\" aligh=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus far we studied that diversification is key and that portfilio with diversified portflio reduce the risk, now let's see how to compare portfolio's and identify the ones giving is maximum gain with least risk...\n",
    "\n",
    "Refresher - \n",
    "\n",
    "Portfolio's return depends on weighted sum of each stock expected return.\n",
    "\n",
    "Portfolio's variance is the pair-wise covariances weighted by the product of the weights..\n",
    "\n",
    "<img src=\"Images/225.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "So let's take an example if each stock is 20% of portfolio how does the portlio perfom in terms of return and volatility ...\n",
    "\n",
    "<img src=\"Images/226.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "So return is 3% and volatility is 4% -- not sure if this is right strartegy in terms if weights, so let's try different distribution of stocks to see how does the portfolio perform ....\n",
    "\n",
    "<img src=\"Images/227.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "So as we see above after running few different distributions the problem is even more interesting, first two show same risk but first distrubtion yield better results, last row shows best return but higest risk, so let's run it for thoursands more possible combinations and see what does that run give us as outcome .. \n",
    "\n",
    "So the run below is for 25000 various combinations, where each dot give us scenario with risk and return, let's study 2 dots, we see that for same risk, RED dot give us much more return...\n",
    "<img src=\"Images/228.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Now let's expand the perspctive studing whole data set, what we see if the top curve which are max returns scenarios will return given risk which is so cool! \n",
    "<img src=\"Images/229.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "And building upon the same analogy, what we see if that returns over the curve are unachivable with given combination of stocks and similarly area below curve shows achievability but are inefficient, one may wonder why would any investor try these knowingly there are better yielding stratgies..\n",
    "\n",
    "<img src=\"Images/230.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "The lower Specturm is called Min Variance Portfolio and Upper is called Market POrtfolio\n",
    "<img src=\"Images/232.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Given above understanding, we can define 'Effcient Frontier' as \n",
    "\n",
    "<img src=\"Images/231.png\" width=\"500\" height=\"500\" aligh=\"left\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So we learnt cool techniques thus far to build optimal portflios, but can we do better than this? Let's see..\n",
    "\n",
    "So we will introduce risk free assets, technically there is nothing risk free in reality but return on ** 3 Month Treasury Bill is considered risk free! **\n",
    "\n",
    "<img src=\"Images/233.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "<img src=\"Images/234.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "So let's add risk free instrument to any portfolio, and let's study two points risk-free asset & any point on Efficient Frontier. Line between them is potential portfolios one can create between two assets. \n",
    "\n",
    "<img src=\"Images/235.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "So which portflio to choose from on the Efficient Frontier end, for that draw the straight line and choose the portfolio which touches the intersection of straight line and curve...\n",
    "\n",
    "<img src=\"Images/236.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "To see why this the best choice, so let's draw few projections, as it is evident that Line A gives best return give risk in contrast to Line B and Line C & so line is called Capital Market Line.\n",
    "\n",
    "<img src=\"Images/237.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "<img src=\"Images/238.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "So the portflio return would be then (this depending on what risk investor decide to choose from): \n",
    "\n",
    "<img src=\"Images/239.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "**Sharpe Ratio** the slope of the Market Capital Line is called the Sharpe Ratio..\n",
    "\n",
    "<img src=\"Images/240.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "**Interestingly, if one can leverage (borrow) from risk free rate, one can achieve points to the right on the capital market line. This amounts to setting negative weight on the risk free asset. That is to say shorting it. This why professional investors almost onlt care about the Sharpe Ratio, because thet can manufacture any amount of risk or return with this leverage**\n",
    "\n",
    "<img src=\"Images/241.png\" width=\"500\" height=\"500\" aligh=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sharpe Ratio in detail\n",
    "<img src=\"Images/242.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/243.png\" width=\"500\" height=\"500\" aligh=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Risk Measures\n",
    "\n",
    "<img src=\"Images/244.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/245.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/246.png\" width=\"500\" height=\"500\" aligh=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CAPM\n",
    "\n",
    "<img src=\"Images/247.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/248.png\" width=\"500\" height=\"500\" aligh=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio Optimization\n",
    "\n",
    "Optimization can be representative of finding Maxima or Minima of a function..\n",
    "\n",
    "<img src=\"Images/249.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/250.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "<img src=\"Images/251.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/252.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "In real world though Optimizations would have constraints, i.e. we will have to see Optimization Problems considering constraints\n",
    "\n",
    "<img src=\"Images/253.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Let's see in detail on can the Functions determing these can handle constrainst ...\n",
    "\n",
    "The Function which is being Optimized is called **Objective or Cost Function**\n",
    "\n",
    "<img src=\"Images/254.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "And the variables we are trying to optimize are nothing but weights of stocks in portfoilio (in this case-study) are called **Optimization Variables**\n",
    "\n",
    "<img src=\"Images/255.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "And then we have constraints which take form of various equalities or inequatlities & if problem has no constraints it is called 'unconstrained problem' -\n",
    "\n",
    "<img src=\"Images/256.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Taking an example : \n",
    "\n",
    "<img src=\"Images/257.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/258.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/259.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "So there got be at least one feasible point else it is called unfeasible problem or unbounded flow\n",
    "\n",
    "<img src=\"Images/260.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "General Optimization problem can be very difficult to solve, one can have objective function of many variables and constraints can be very complicated ...\n",
    "<img src=\"Images/261.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "so instead of thinking how to solve all,  let's focus on certain types which are solvable and relevant, one of the types where Objective Function and Inequalities constraints are Convex...\n",
    "\n",
    "<img src=\"Images/262.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/263.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "One of the huge benefits is that if we hit minimum, we know that it is global minimum as there is no local mimimum or in other words local min is the global min... these can be summed as properties below, and there are great techniques to solve these\n",
    "\n",
    "<img src=\"Images/264.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/265.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/266.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/267.png\" width=\"500\" height=\"500\" aligh=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/268.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/269.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/270.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/271.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/272.png\" width=\"500\" height=\"500\" aligh=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/273.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/274.png\" width=\"500\" height=\"500\" aligh=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rebalancing Portfolio\n",
    "\n",
    "So let's say we started with 50% investment in Solar and 50% investment in Construction\n",
    "<img src=\"Images/275.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "And over period of time, say Solar grew substantially making it 75% of portfolio so to balance that out, we will have to rebalance.\n",
    "<img src=\"Images/276.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Rebalance has cost to it as listed below\n",
    "<img src=\"Images/277.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "It may not sound obvious so let's look at example on how much these transcation costs can eat up profits.\n",
    "<img src=\"Images/278.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "**Turn-Over**\n",
    "It is hard to estimate transcational cost, hence instead of finding that, we estimate these as proportional to the magnitude of change in holdings. This is called portflio turnover. And it is bsically the sum total changes in the weights on all the assets - to calculate this, we will take the absolute value of the difference in weights between two time periods for each asset and then sum these over assets.\n",
    "<img src=\"Images/279.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "To annulaize turn-over.\n",
    "<img src=\"Images/280.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "So when to Rebalance ??\n",
    "\n",
    "<img src=\"Images/281.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/282.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Rebalance Stratigies:\n",
    "1. Temporal i.e. at some fixed time frequency, regardless of other factors - this frequency on when to rebalance is mostly the similar frequency analysts used to study and define the model, example if model was build using montly data time windows, then rebalancing will be needed monthly as models may not be effective post month.\n",
    "<img src=\"Images/283.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "2. Threshold Based: In this case time horizon is not a factor rather distribution or weights for assets is the key, as n when they change may trigger need to rebalance.\n",
    "\n",
    "3. Hybrid:\n",
    "\n",
    "Both above stratigies can be combined to triggere rebalancing decision and time...\n",
    "\n",
    "<img src=\"Images/284.png\" width=\"500\" height=\"500\" aligh=\"left\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations to Portfoio Planning & Optimization\n",
    "\n",
    "<img src=\"Images/285.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Not going in mitigations as most will be discussed later.\n",
    "\n",
    "Multi-Period Optimization & Factor Based Modeling are some of the techniques which can overcome challenges..\n",
    "\n",
    "Multi-Period Optimization\n",
    "If you're curious, you can find out more about multi-period optimization here (http://stanford.edu/~boyd/papers/pdf/cvx_portfolio.pdf).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leg 3 of Term 1 -- putting all other and learning some new fundamenals "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to realize factors making decision for buy & trade\n",
    "\n",
    "<img src=\"Images/286.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/287.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/288.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/289.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Example of Factor, let's say MOMENTUM\n",
    "<img src=\"Images/290.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "After reading below, should we use this for predicting prices? that would be difficult, but we can surely use it for deciding weights or choosing stocks in portflio. Let's take an example below on how two companies momentum on retruns can be helpful making decision with weights \n",
    "\n",
    "<img src=\"Images/291.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/292.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "**Standardizing the Factor** : Since Factors are nothing but raw numerical values, we must standardize them before we can put them to use..\n",
    "\n",
    "<img src=\"Images/293.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Above may sound confusing, and can be applied in either manner, so let's look at example below to clearly understand this ..\n",
    "<img src=\"Images/294.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "**DE-MEAN in DEPTH**\n",
    "So why do we de-mean, one of the main reasons is that Stocks in portfolio are difference price range, so stocks with higher price have  higher raw values for factors (say momentum) for comparison between 2 stocks though relatively they may mean the same momentum. So to neutralize the effect of Stock Price, and see the momentum signal evenly across stocks of different prices, standarrizing them is very important. \n",
    "\n",
    "Another aspect is that signals move in contrast with market, so Long Portflio will move along market and short portflio will move opposite to market, **Dollar Neutral** is a special case where portflio is even distribution of long and short or in essence **Market Neutral**\n",
    "\n",
    "<img src=\"Images/295.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/296.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "We can also also see concept of **Dollar/Market Neutral** in terms of Stocks Weights. To do this we will need to understand new term called **Notional**, notional is nothing but stock weight times portflio value. So below is an example of how this would play out ..\n",
    "\n",
    "Note the TOTAL below post summing up investment, in this case we are assuming only two stocks in portflio.\n",
    "\n",
    "<img src=\"Images/297.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Let's apply this realitsically, let's say we have 2 stocks of withe below distribution as non-dollar neutral, we see that relative difference between stocks is .20\n",
    "\n",
    "<img src=\"Images/298.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "So by applying this relative difference we can make the portfolio Dollar Neutral\n",
    "\n",
    "<img src=\"Images/299.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "So how did we compute the delta, we computed mean and did difference between mean and distribution, this concept is very familiar and nothing but de-mean what we studied above..\n",
    "\n",
    "<img src=\"Images/300.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "\n",
    "**RE_SCALING in DEPTH**\n",
    "\n",
    "So why do we rescale the weights, where they add up to 1 ??\n",
    "\n",
    "Before this let's understand what leverage means: \n",
    "<img src=\"Images/301.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/302.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "So if leveraging good? Not necessarily, as it exponentially increase our risk for losses as well in addition to gains.\n",
    "Useful measure to understand would be Leverage Ratio\n",
    "\n",
    "<img src=\"Images/303.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Leverage Ratio Increases as Investment Increases\n",
    "<img src=\"Images/304.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "With theoritical Notional of Dollar 1, some example below, we will skip division as divide by 1 is same..\n",
    "<img src=\"Images/305.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Going back to original goal, we will perform recsaling so that we have leverage ratio add up to 1 by doing this:\n",
    "<img src=\"Images/306.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Summarizing All:\n",
    "<img src=\"Images/307.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Exercise:\n",
    "<img src=\"Images/308.png\" width=\"500\" height=\"500\" aligh=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zipline Python\n",
    "\n",
    "Lab in Quizes folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Factor and Factor Modeling\n",
    "\n",
    "<img src=\"Images/309.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/310.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Latent Variables are the ones which can qualified but not quantified/measured that easily.\n",
    "Above approach seems very familar with Multiple Linear Regression ...\n",
    "\n",
    "<img src=\"Images/311.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Assumptions, term s is not depedent on factors and rather specific (idiosyncratic) to the asset, and hence the coorelation factor as 0\n",
    "\n",
    "<img src=\"Images/312.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "The above does help rule out many possibilities with the regression, but it comes at cost that greater the chanceof it being wrong & hence multiple factors are used to have more credible outcomes - but simpliclity of model is also key as our goal is to read signal than noise.\n",
    "\n",
    "<img src=\"Images/313.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "In below equation, r{i} is asset return per asset (random), B is fixed, f is random & s is asset specfic idiosyncratic return\n",
    "<img src=\"Images/314.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Our goal is to find Covariance between asset returns\n",
    "<img src=\"Images/315.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Remember the generic equation of covariance, but since we have mean as zero (we de-mean prior) - it simplify to expectation of assets\n",
    "<img src=\"Images/316.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "And Expectation Matrix is nothing but Expectation Value applied to each element.\n",
    "<img src=\"Images/317.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Matrix of r is nothing but\n",
    "<img src=\"Images/318.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "So covariance can be re-written as \n",
    "<img src=\"Images/319.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "and further simply as\n",
    "<img src=\"Images/320.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Factor Models are not ideally used to model asset returns (there is long history to this), rather one the key uses are optimization of portfolios\n",
    "\n",
    "Quants make simplication of the equation we derived, let's spotlight in Factor Exposures i.e. Matrix B, where we know that it as elements define sesitivity to each asset, so this Matrix with weight x is nothing but B transpose x\n",
    "\n",
    "<img src=\"Images/321.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Let's introduce a new idea, where we say  that there are 2 types of factors, one which is Predictive of Mean Returns (i.e Alpha Factors)\n",
    "\n",
    "<img src=\"Images/322.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "and other is Predictive of the Variance of the Returns (i.e. Risk)\n",
    "\n",
    "<img src=\"Images/323.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "So we would rather minimize exposure to RISK, and attempt to optimize/contrain components in Matrix which are sensitive to risks & help us reduce the exposure to risk factors.\n",
    "\n",
    "<img src=\"Images/324.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "On contrary, we do not contrain the Alpha Fcators, rather take them out of B, so now B is reflection of RISK factors as ALPHA has been taken out ...\n",
    "\n",
    "<img src=\"Images/325.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "so what about F and S ??\n",
    "<img src=\"Images/326.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "**So the key take away is that B&F are RISK only and S say nothing explicit about Alpha, generally Qants BUY F, S and B from commercial providers - generally these are contained with Alpha driving optimization**\n",
    "\n",
    "<img src=\"Images/327.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "So what do we do with Alpha which we took out, these will be comdensed as vetor of weights later and will be used in Optimizations\n",
    "\n",
    "<img src=\"Images/328.png\" width=\"500\" height=\"500\" aligh=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/329.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/330.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/331.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/332.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/333.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "<img src=\"Images/334.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/335.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "<img src=\"Images/336.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/337.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "<img src=\"Images/338.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/339.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "When ALPHA Factors becomes RISK Factor, Alpha factors will eventually loose their performance, as once these factors have started to be adopted by many parties, they all start to exhibit similar patterns moving tades in the same direction, and hence creating more variance than predictive indicator to gain...\n",
    "\n",
    "<img src=\"Images/340.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/341.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "**Factors can be broadly classified as Momentum Or Reversal**\n",
    "<img src=\"Images/342.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/343.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/344.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Price-Volume Factors\n",
    "<img src=\"Images/345.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/346.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Below, Mean is the center of the returns, spread/variance (square of variance is volatility), Skew (+ve tells more extreme values on +ve side of the distribution), Kurtosis (Fat Tail, are normal with stocks and refer as distributions in tails)\n",
    "<img src=\"Images/347.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/348.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "<img src=\"Images/349.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Volume Factors\n",
    "<img src=\"Images/350.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/351.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/352.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Fundamentals as Alpha\n",
    "<img src=\"Images/353.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Why below, because Earings could be zero & may lead to calculation erros -- 'Book to Price' ratio, Cash Flow, EBITA (Earnings Before Interest Tax Depreciation & Amortization) could be alternative  \n",
    "<img src=\"Images/354.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Cash FLows however could be more volatile and jumpy; as it states cash going in and out, example cash flow may be huge when company expensive equipments hence earnings may be smoother as accountants apply accounting mellowing down, example prorate cost over life of company..\n",
    "\n",
    "Event Driven Factors\n",
    "\n",
    "Some examples of one-off events\n",
    "<img src=\"Images/355.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "some examples of regular events\n",
    "<img src=\"Images/356.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Index Events/Signals\n",
    "Since incidicies are heavily relied building stock portfolios, measuring performances, adding or deletion impact stock prices.\n",
    "\n",
    "<img src=\"Images/357.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/358.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Pre-Post Events\n",
    "<img src=\"Images/359.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Analyst Rating Events\n",
    "<img src=\"Images/360.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Alternative Data Events - These could be anything outside public financials, like sentiments on social media, satelite images etc\n",
    "\n",
    "Sentiment and Social News Media Events - News Channels, Social Media Posts etc can be used using NLP to create Alpha Factors\n",
    "\n",
    "NLP can however be used for much more than Sentiment Analysis as show below:\n",
    "<img src=\"Images/361.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Sector Classification using 10k : https://www.winton.com/research/systematic-methods-for-classifying-equities\n",
    "10k Study :https://www.sec.gov/fast-answers/answersreada10khtm.html\n",
    "\n",
    "Alternative Data\n",
    "(Computer Vision can be used to scan aerial images generating signals)\n",
    "\n",
    "<img src=\"Images/362.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/363.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/364.png\" width=\"500\" height=\"500\" aligh=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risk Factor Models\n",
    "\n",
    "<img src=\"Images/365.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/366.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "<img src=\"Images/367.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/368.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/369.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/370.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "**Refresher - Factor Model Asset Return**\n",
    "<img src=\"Images/371.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/372.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/373.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/374.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/375.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "So let's see how to do this for portfolio\n",
    "<img src=\"Images/376.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/377.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/378.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/379.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Similarly, we can measure portfolio variance as \n",
    "<img src=\"Images/380.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "<img src=\"Images/381.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/382.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/383.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/384.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "So why the constant (Beta) gets squared when we take it out\n",
    "<img src=\"Images/385.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/386.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/387.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/388.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "By definition  specific returns are uncorelated with factors, so the covariances are zero for these terms & rest remains intact \n",
    "<img src=\"Images/389.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/390.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "so in summary\n",
    "<img src=\"Images/391.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/392.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/393.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "So let's see how to apply above knowledge to find variance of a portfolio\n",
    "<img src=\"Images/394.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Let's break down above equation to see how it is computed..\n",
    "<img src=\"Images/395.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/396.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "For next steps we will study various risk models...\n",
    "<img src=\"Images/397.png\" width=\"500\" height=\"500\" aligh=\"left\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series and Cross Sectional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/398.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/399.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/400.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/401.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/402.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "**So let's build up to add two new factors namely Size and Value, to existing Market Return making it a popular 3 factor model called 'Fama French Model'**\n",
    "\n",
    "Let's take example of Small Cap Stock and Large Cap Stock, \n",
    "<img src=\"Images/403.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Let's say if we had evidence that small cap stocks yield higher than avergae returns, wht would you do as rational investor??\n",
    "One strategy could be to buy small cap stocks and short large cao stocks.\n",
    "\n",
    "<img src=\"Images/404.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "So can we now say that tending these, if size of the company matters, the below trend give us a new factor 'Size' which seems to be giving cleat trend in daily basis on distribution of stocks influencing returns...\n",
    "\n",
    "<img src=\"Images/405.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/406.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/407.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "**Now let's talk about Value Factor**\n",
    "\n",
    "Similar to above:\n",
    "<img src=\"Images/408.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/409.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Let's see how Fama combine these models to generate time series model\n",
    "<img src=\"Images/410.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "\n",
    "Since HML does not use Neural Value Segment, we will divide these by their distribution to generalize.\n",
    "<img src=\"Images/411.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "\n",
    "<img src=\"Images/412.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/413.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/414.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/415.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/416.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/417.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/418.png\" width=\"500\" height=\"500\" aligh=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CROSS SECTIONAL RISK MODEL**\n",
    "\n",
    "<img src=\"Images/419.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/420.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "The text in orange are predicted, which sounds confusing as we predict Betas(exposure) knowing Factors in Time Series Risk Model, conversely predict Factors knowing the Betas(exposure) ahead of time...\n",
    "\n",
    "This sounds really confusing, let's study it a bit more...\n",
    "<img src=\"Images/421.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/422.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "Let's move ahead with Cross-Sectional...\n",
    "There are some factors lik country of origin, which may impact stock, say some legislation impact only US impacting stock prices overall, so how do we handle this, since these are non-numerical values, one-hot encoded values will act as factors, won;t go much in depth in here as I know already know about this ...\n",
    "<img src=\"Images/423.png\"e width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "So how do we apply this?\n",
    "\n",
    "<img src=\"Images/424.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/425.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/426.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/427.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/428.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/429.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/430.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "What about S ?\n",
    "<img src=\"Images/431.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "So how fundamental factors applied to Cross Section Risk Model\n",
    "<img src=\"Images/432.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/433.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/434.png\" width=\"500\" height=\"500\" aligh=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary: In acadmia, researchers use the Time-Series Risk model approach, where as in industry practioners use Commericial Risk Models which are primarily based on Cross-Sectional Risk Models, these commerical models are further purchased from/built/maintianed by MSCI Barra, Axioma or Northfield. Alternatively, they may use the 3rd approch called PCA (Principal Compoent Analysis) which we will study ahead.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Risk Factor Models with PCA\n",
    "\n",
    "I will not go explain PCA, simply look at PCA Quiz (pca_basics) in the Quizes folder. We know that once we run PCA, we get new representation on the old data which we call Principal Components. And we further we look at PCs which try to cover most of the variance, i.e. it helps reduce the dimensinality of the data, but keep the information close to actual helping us learn and build decision process on.\n",
    "\n",
    "So let's apply this to our world! Let's start with what we have at hand ... \n",
    "\n",
    "<img src=\"Images/435.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "which can we described via formula:\n",
    "\n",
    "<img src=\"Images/436.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "and in matrices form be written as below, and each of these matrix has dimesions whcih can be explained their last units say N,T which means, number of companies by number if time points.\n",
    "\n",
    "<img src=\"Images/437.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "\n",
    "Then we run PCA, which gives us PCs decscribing the old data in PC language\n",
    "<img src=\"Images/438.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "The we pick PCA based on our threshold of variance and reduce dimentionality\n",
    "\n",
    "<img src=\"Images/439.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/440.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "\n",
    "The easy way to study how this is applied is to look at the quiz (pca_factor_model) but some formulas below which may speed up understanding.\n",
    "\n",
    "<img src=\"Images/441.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/442.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/443.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/444.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/445.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/446.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/447.png\" width=\"500\" height=\"500\" aligh=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alpha Factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/448.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/449.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/450.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/451.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/452.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/453.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "<img src=\"Images/454.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/455.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/456.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/457.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/458.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/459.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/460.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "<img src=\"Images/461.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/462.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/463.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/464.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/465.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/466.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/467.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/468.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "<img src=\"Images/468_1.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/469.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/470.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/471.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/472.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/473.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/474.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/475.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/476.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/477.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/478.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/479.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/480.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "<img src=\"Images/481.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/482.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/483.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/484.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/485.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/486.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/487.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/488.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/489.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/490.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/491.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/492.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/493.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/494.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/495.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/496.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/497.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/498.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/499.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/450.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/451.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/452.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/453.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/454.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/455.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/456.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/457.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/458.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/459.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/460.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/461.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/462.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/463.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/464.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/465.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/466.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/467.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/468.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/469.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/470.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/471.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/472.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/473.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/474.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/475.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/476.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/477.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/478.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/479.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/480.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/481.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/482.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/483.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/484.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/485.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/486.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/487.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/488.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/489.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/490.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/491.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/492.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/493.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/494.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/495.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/496.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/497.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/498.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/499.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/500.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/501.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/502.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/503.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/504.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/505.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/506.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/507.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/508.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/509.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/510.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/511.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/512.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/513.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/514.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/515.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/516.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/517.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/518.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/519.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/520.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/521.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/522.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/523.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/524.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/525.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/526.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/527.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/528.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/529.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/530.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/531.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/532.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/533.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/534.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/535.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/536.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/537.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/538.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/539.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/540.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/541.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/542.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/543.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/544.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/545.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/546.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/547.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/548.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/549.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/550.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/551.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/552.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/553.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/554.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/555.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/556.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/557.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/558.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/559.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/560.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/561.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/562.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/563.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/564.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/565.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/566.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/567.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/568.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/569.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/570.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/571.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/572.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/573.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/574.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/575.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/576.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/577.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/578.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/579.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/580.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/581.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/582.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/583.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/584.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/585.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/586.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/587.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/588.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/589.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/590.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/591.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/592.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/593.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/594.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/595.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/596.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/597.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/598.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/599.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/600.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/601.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/602.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/603.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/604.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/605.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/606.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/607.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/608.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/609.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/610.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/611.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/612.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/613.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/614.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/615.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/616.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/617.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/618.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/619.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/620.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/621.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/622.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/623.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/624.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/625.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/626.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/627.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/628.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/629.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/630.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/631.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/632.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/633.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/634.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/635.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/636.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/637.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/638.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/639.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/640.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/641.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/642.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/643.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/644.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/645.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/646.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/647.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/648.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/649.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/650.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/651.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/652.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/653.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/654.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/655.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/656.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/657.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/658.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/659.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/660.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "<img src=\"Images/661.png\" width=\"500\" height=\"500\" aligh=\"left\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Do Stock Prices Fully Reflect Information in Accruals and Cash Flows about Future Earnings? -- Richard Sloan\n",
    "http://econ.au.dk/fileadmin/Economics_Business/Education/Summer_University_2012/6308_Advanced_Financial_Accounting/Advanced_Financial_Accounting/2/Sloan_1996_TAR.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alpha Factor Reserach Methods\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Overnight Returns and Firm-Specific Investor Sentiment : https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2554010\n",
    "\n",
    "The Formation Process of Winners and Losers in Momentum Investing : https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2610571\n",
    "\n",
    "Expected Skewness and Momentum : https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2600014\n",
    "\n",
    "Arbitrage Asymmetry and the Idiosyncratic Volatility Puzzle : https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2155491\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
